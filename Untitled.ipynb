{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b05588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b341c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97763381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d2ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from flask import Flask, request, render_template\n",
    "from flasgger import Swagger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "app = Flask(__name__)\n",
    "model = pickle.load(open('rf.pkl', 'rb'))\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict_iris():\n",
    "\n",
    "    int_features = [int(x) for x in request.form.values()]\n",
    "    final_features = [np.array(int_features)]\n",
    "    \n",
    "    prediction = model.predict(final_features)\n",
    "\n",
    "    return render_template('index.html', prediction_text='Type of the Iris is {}'.format(prediction[0]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85708002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ce52b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "418592a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e321d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "body='''\n",
    "Versatile way to cleanse your face. Comes with 3 brush heads and I have sensitive skin so use it 1x per day instead of 2x with the brush for sensitive skin.\n",
    "If you have oily skin or skin with acne, it is recommended to clean the skin twice a day.\n",
    "My skin feels firmer, smoother and more radiant since I bought it.\n",
    "I use it in combination with Cerave cleanser for sensitive skin.\n",
    "Suitable for use in the shower. (Is splash proof.)\n",
    "I don't do that because washing your face with lukewarm water is better.\n",
    "Since I got it, I've only charged it once and the battery just keeps on working.\n",
    "Has a handy 3x 20 second timer so you never scrub your face for too long.\n",
    "(Left side of your face, right side and t-zone.)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "264f9e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(body) < 50:\n",
    "    print(\"Not enought words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f7dea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_len = int(len(body)*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8bd134a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73450605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# use bart in pytorch\n",
    "summarizer = pipeline(\"summarization\")\n",
    "summary = summarizer(body, min_length=50, max_length=sum_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6212ab7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if you have oily skin or skin with acne, it is recommended to clean the skin twice a day . comes with 3 brush heads and has a handy 3x 20 second timer so you never scrub your face for too long .'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3869b977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66eda784",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nPegasusForConditionalGeneration requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-7b1166557421>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cuda'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPegasusTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPegasusForConditionalGeneration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'longest'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mtranslated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\utils\\dummy_pt_objects.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2106\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2108\u001b[1;33m         \u001b[0mrequires_pytorch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mrequires_pytorch\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__name__\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPYTORCH_IMPORT_ERROR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: \nPegasusForConditionalGeneration requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n"
     ]
    }
   ],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import torch\n",
    "src_text = [\n",
    "    \"\"\" PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\"\"\n",
    "]\n",
    "\n",
    "model_name = 'google/pegasus-xsum'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "batch = tokenizer(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(torch_device)\n",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "assert tgt_text[0] == \"California's largest electricity provider has turned off power to hundreds of thousands of customers.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f345e6d1",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "921e67c0",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "if physical_devices:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65cfdc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd06f0105f9397998aabf0bf1920609558408ae3734a3428bdac0deeef582aa0c0a",
   "display_name": "Python 3.8.8 64-bit ('NLP': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}